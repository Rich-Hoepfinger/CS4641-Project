{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rma86/Library/CloudStorage/OneDrive-GeorgiaInstituteofTechnology/2023Spring/CS4641/CS4641-Project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# os.chdir('./CS4641-Project/')\n",
    "print(os.getcwd())\n",
    "# Make sure you are at project root directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collinearity_v2\n",
    "import new_dbscan_v2\n",
    "import zscore\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn import neural_network\n",
    "from sklearn import metrics\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import new_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pandas.read_csv('minmax_normalised_trackdata.csv')\n",
    "#data = pandas.read_csv('dupremoved_trackdata.csv')\n",
    "#data = pandas.read_csv('softmax_normalised_trackdata.csv')\n",
    "#data = pandas.read_csv('zscore_normalised_trackdata.csv')\n",
    "\n",
    "# data = pandas.read_csv('outlier_removal/automated_dbscanned_trackdata.csv',index_col=0)\n",
    "data = pd.read_csv('outlier_removal/automated_collinearity_removed.csv')\n",
    "\n",
    "genreMap = sorted(data[\"genre\"].unique())\n",
    "y = preprocessing.LabelEncoder().fit_transform(data[\"genre\"])\n",
    "X = data.drop(\"genre\", axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net():\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25)\n",
    "    scaler = StandardScaler()  \n",
    "    scaler.fit(X_train)  \n",
    "    X_train = scaler.transform(X_train)  \n",
    "    X_test = scaler.transform(X_test)\n",
    "    model = neural_network.MLPClassifier(activation= 'tanh', max_iter= 1000000).fit(X_train, y_train)  \n",
    "\n",
    "\n",
    "    yPredicted = model.predict(X_test)\n",
    "    with open('outlier_removal/tests_v2.txt','a') as f:\n",
    "        accuracy = metrics.accuracy_score(y_test, yPredicted).round(3)\n",
    "        precision = metrics.precision_score(y_test, yPredicted, average=\"macro\").round(3)\n",
    "        recall = metrics.recall_score(y_test, yPredicted, average=\"macro\").round(3)\n",
    "        f.write(\"\\nModel: Neural Net\")\n",
    "        f.write(\"\\nAccuracy: \" + str(accuracy))\n",
    "        f.write(\"\\nPrecision: \" + str(precision))\n",
    "        f.write(\"\\nRecall: \" + str(recall) + \"\\n\")\n",
    "        return accuracy\n",
    "\n",
    "def SVM():\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25)\n",
    "    scaler = StandardScaler()  \n",
    "    scaler.fit(X_train)  \n",
    "    X_train = scaler.transform(X_train)  \n",
    "    X_test = scaler.transform(X_test)\n",
    "    model = svm.SVC(C = 1.5, kernel = 'rbf', degree = 9, gamma = 'scale', decision_function_shape= 'ovo').fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    yPredicted = model.predict(X_test)\n",
    "    with open('outlier_removal/tests_v2.txt','a') as f:\n",
    "        accuracy = metrics.accuracy_score(y_test, yPredicted).round(3)\n",
    "        precision = metrics.precision_score(y_test, yPredicted, average=\"macro\").round(3)\n",
    "        recall = metrics.recall_score(y_test, yPredicted, average=\"macro\").round(3)\n",
    "        f.write(\"\\nModel: SVM\")\n",
    "        f.write(\"\\nAccuracy: \" + str(accuracy))\n",
    "        f.write(\"\\nPrecision: \" + str(precision))\n",
    "        f.write(\"\\nRecall: \" + str(recall) + \"\\n\")\n",
    "        return accuracy\n",
    "    \n",
    "def decision_tree():\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25)\n",
    "    scaler = StandardScaler()  \n",
    "    scaler.fit(X_train)  \n",
    "    X_train = scaler.transform(X_train)  \n",
    "    X_test = scaler.transform(X_test)\n",
    "    model = tree.DecisionTreeClassifier(criterion = 'entropy', splitter = 'best').fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    yPredicted = model.predict(X_test)\n",
    "    with open('outlier_removal/tests_v2.txt','a') as f:\n",
    "        accuracy = metrics.accuracy_score(y_test, yPredicted).round(3)\n",
    "        precision = metrics.precision_score(y_test, yPredicted, average=\"macro\").round(3)\n",
    "        recall = metrics.recall_score(y_test, yPredicted, average=\"macro\").round(3)\n",
    "        f.write(\"\\nModel: Decision Tree\")\n",
    "        f.write(\"\\nAccuracy: \" + str(accuracy))\n",
    "        f.write(\"\\nPrecision: \" + str(precision))\n",
    "        f.write(\"\\nRecall: \" + str(recall) + \"\\n\")\n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_threshold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m f\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mBest Min_points: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(best_min_points))\n\u001b[1;32m     36\u001b[0m f\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mBest Epsilon: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(best_eps))\n\u001b[0;32m---> 37\u001b[0m f\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mBest Threshold: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(best_threshold))\n\u001b[1;32m     38\u001b[0m f\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mBest Metric: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(best_method))\n\u001b[1;32m     39\u001b[0m f\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mRemoved Songs: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(best_removed_songs))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_threshold' is not defined"
     ]
    }
   ],
   "source": [
    "#dupremoved -> dbscan -> zscore -> k nearest neighbors (no collinearity elimination)\n",
    "best_accuracy = 0\n",
    "best_min_points = 0\n",
    "best_eps = 0\n",
    "methods = [\"euclidean\", \"cosine\", \"cityblock\", \"l1\", \"l2\", \"hamming\"]\n",
    "best_method = None\n",
    "prev_removed_songs = 0\n",
    "best_removed_songs = 0\n",
    "threshold = 1\n",
    "for method in methods:\n",
    "    for min_points in range(1, 10):\n",
    "        prev_removed_songs = 0\n",
    "        for eps in np.arange(5, 20):\n",
    "            removed_songs = new_dbscan_v2.dbscan_main(eps=eps, min_points=min_points,metric=method)\n",
    "            if removed_songs == 0:\n",
    "                with open('outlier_removal/tests_v2.txt','a') as f:\n",
    "                    f.write(\"\\nRemoved Songs is 0, moving on...\\n\")\n",
    "                break\n",
    "            if removed_songs == prev_removed_songs:\n",
    "                with open('outlier_removal/tests_v2.txt','a') as f:\n",
    "                    f.write(\"\\nRemoved Songs is the Same, moving on...\\n\")\n",
    "                break\n",
    "            prev_removed_songs = removed_songs\n",
    "            zscore.zscore_main()\n",
    "            collinearity_v2.remove_collinearity(threshold=threshold)\n",
    "            accuracy = SVM()\n",
    "            if best_accuracy < accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_min_points = min_points\n",
    "                best_eps = eps\n",
    "                best_method = method\n",
    "                best_removed_songs = prev_removed_songs\n",
    "with open('outlier_removal/tests_v2.txt','a') as f:\n",
    "    f.write(\"\\nBest Accuracy: \" + str(best_accuracy))\n",
    "    f.write(\"\\nBest Min_points: \" + str(best_min_points))\n",
    "    f.write(\"\\nBest Epsilon: \" + str(best_eps))\n",
    "    f.write(\"\\nBest Metric: \" + str(best_method))\n",
    "    f.write(\"\\nRemoved Songs: \" + str(best_removed_songs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dupremoved -> dbscan -> zscore -> collinearity -> k nearest neighbors\n",
    "best_accuracy = 0\n",
    "best_min_points = 0\n",
    "best_eps = 0\n",
    "methods = [\"euclidean\", \"cosine\", \"cityblock\", \"l1\", \"l2\", \"hamming\"]\n",
    "best_method = None\n",
    "prev_removed_songs = 0\n",
    "best_removed_songs = 0\n",
    "best_threshold = 0\n",
    "for method in methods:\n",
    "    for min_points in range(1, 10):\n",
    "        for eps in np.arange(5, 20):\n",
    "            prev_removed_songs = 0\n",
    "            for th in np.arange(0.5, 0.9, 0.1):\n",
    "                removed_songs = new_dbscan_v2.dbscan_main(eps=eps, min_points=min_points,metric=method)\n",
    "                if removed_songs == 0:\n",
    "                    with open('outlier_removal/tests_v2.txt','a') as f:\n",
    "                        f.write(\"\\nRemoved Songs is 0, moving on...\\n\")\n",
    "                    break\n",
    "                if removed_songs == prev_removed_songs:\n",
    "                    with open('outlier_removal/tests_v2.txt','a') as f:\n",
    "                        f.write(\"\\nRemoved Songs is the Same, moving on...\\n\")\n",
    "                    break\n",
    "                prev_removed_songs = removed_songs\n",
    "                zscore.zscore_main()\n",
    "                collinearity_v2.remove_collinearity(threshold=threshold)\n",
    "                accuracy = SVM()\n",
    "                if best_accuracy < accuracy:\n",
    "                    best_accuracy = accuracy\n",
    "                    best_min_points = min_points\n",
    "                    best_eps = eps\n",
    "                    best_method = method\n",
    "                    best_removed_songs = prev_removed_songs\n",
    "                    best_threshold = th\n",
    "with open('outlier_removal/tests_v2.txt','a') as f:\n",
    "    f.write(\"\\nBest Accuracy: \" + str(best_accuracy))\n",
    "    f.write(\"\\nBest Min_points: \" + str(best_min_points))\n",
    "    f.write(\"\\nBest Epsilon: \" + str(best_eps))\n",
    "    f.write(\"\\nBest Threshold: \" + str(best_threshold))\n",
    "    f.write(\"\\nBest Metric: \" + str(best_method))\n",
    "    f.write(\"\\nRemoved Songs: \" + str(best_removed_songs))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
